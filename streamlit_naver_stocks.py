# -*- coding: utf-8 -*-
import os, re, io, time, json, requests
import pandas as pd
from bs4 import BeautifulSoup
import streamlit as st
import plotly.express as px
from collections import defaultdict
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê¸°ë³¸ ì„¤ì • ë° ìƒíƒœ ì´ˆê¸°í™”
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
st.set_page_config(page_title="ë„¤ì´ë²„ ìž¬ë¬´ í¬ë¡¤ëŸ¬", layout="wide")
st.title("ðŸ“Š ë„¤ì´ë²„ ì¦ê¶Œ ê¸°ì—…ì •ë³´ ë·°ì–´")

if "data_cache" not in st.session_state:
    st.session_state.data_cache = {}

if "loaded" not in st.session_state:
    st.session_state.loaded = False

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸ í•¨ìˆ˜
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def to_number(s):
    if s is None:
        return None
    s = str(s).strip()
    if s in ("", "-"):
        return None
    s = s.replace(",", "")
    m = re.fullmatch(r"\(([-+]?\d*\.?\d+)\)", s)
    if m:
        return -float(m.group(1))
    try:
        return float(s)
    except Exception:
        return None

def _clean_text(x: str) -> str:
    return re.sub(r"\s+", " ", (x or "").replace("\xa0", " ").strip())

def _extract_year_label(x: str) -> str:
    if not isinstance(x, str):
        x = str(x)
    m = re.search(r"(20\\d{2})(?:[./-]?(?:0?[1-9]|1[0-2]))?", x)
    return m.group(1) if m else x

def to_excel_bytes(df: pd.DataFrame, sheet_name: str = "Sheet1") -> bytes:
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        df.to_excel(writer, index=False if df.index.name is None else True, sheet_name=sheet_name)
    buf.seek(0)
    return buf.read()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# encparam / id íšë“
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@st.cache_data(show_spinner=False)
def get_encparam_and_id(cmp_cd: str, page_key: str) -> dict:
    chrome_options = Options()
    chrome_options.add_argument("--headless=new")
    chrome_options.add_argument("--disable-gpu")
    chrome_options.add_argument("--no-sandbox")
    chrome_options.add_argument("--disable-dev-shm-usage")
    chrome_options.add_argument("--window-size=1920,1080")
    driver = webdriver.Chrome(options=chrome_options)
    try:
        url = f"https://navercomp.wisereport.co.kr/v2/company/{page_key}.aspx?cmp_cd={cmp_cd}"
        driver.get(url)
        time.sleep(2.2)
        html = driver.page_source
        enc_match = re.search(r"encparam\\s*:\\s*['\"]?([a-zA-Z0-9+/=]+)['\"]?", html)
        id_match = re.search(r"cmp_cd\\s*=\\s*['\"]?([0-9]+)['\"]?", html)
        return {
            "cmp_cd": cmp_cd,
            "encparam": enc_match.group(1) if enc_match else None,
            "id": id_match.group(1) if id_match else None,
        }
    finally:
        driver.quit()

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì£¼ìš”ìž¬ë¬´ì •ë³´(HTML í…Œì´ë¸”)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

@st.cache_data(show_spinner=False)
def fetch_main_table(cmp_cd: str, encparam: str, cmp_id: str):
    url = "https://navercomp.wisereport.co.kr/v2/company/ajax/cF1001.aspx"
    headers = {
        'Accept': 'application/json, text/html, */*; q=0.01',
        'User-Agent': 'Mozilla/5.0',
        'X-Requested-With': 'XMLHttpRequest',
        'Referer': f'https://navercomp.wisereport.co.kr/v2/company/c1010001.aspx?cmp_cd={cmp_cd}',
    }
    params = {
        'cmp_cd': cmp_cd,
        'fin_typ': '0',
        'freq_typ': 'Y',
        'encparam': encparam,
        'id': cmp_id,
    }
    res = requests.get(url, headers=headers, params=params, timeout=20)
    res.raise_for_status()
    soup = BeautifulSoup(res.text, 'html.parser')
    tables = soup.select("table.gHead01.all-width")
    target = next((tb for tb in tables if "ì—°ê°„" in tb.text or re.search(r"20\\d\\d", tb.text)), None)
    if not target:
        raise ValueError("ì£¼ìš”ìž¬ë¬´ì •ë³´ í…Œì´ë¸” ì—†ìŒ")

    thead_rows = target.select("thead tr")
    year_cells = thead_rows[-1].find_all(["th", "td"]) if thead_rows else []
    year_counter = defaultdict(int)
    years = []
    for th in year_cells:
        t = _clean_text(th.get_text(" "))
        if t and not re.search(r"ì£¼ìš”ìž¬ë¬´ì •ë³´|êµ¬ë¶„", t):
            year_counter[t] += 1
            suffix = f"_{year_counter[t]}" if year_counter[t] > 1 else ""
            years.append(t + suffix)

    rows = []
    for tr in target.select("tbody tr"):
        th = tr.find("th")
        if not th:
            continue
        metric = _clean_text(th.get_text(" "))
        tds = tr.find_all("td")
        values = []
        for i in range(len(years)):
            raw = tds[i].get("title") or _clean_text(tds[i].get_text(" ")) if i < len(tds) else None
            values.append(to_number(raw))
        rows.append([metric] + values)

    df_wide = pd.DataFrame(rows, columns=["ì§€í‘œ"] + years).set_index("ì§€í‘œ")
    df_long = df_wide.reset_index().melt(id_vars=["ì§€í‘œ"], var_name="ì—°ë„", value_name="ê°’")
    return df_wide, df_long

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Streamlit UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

with st.sidebar:
    st.header("ì„¤ì •")
    cmp_cd = st.text_input("ì¢…ëª©ì½”ë“œ (cmp_cd)", value="005930")
    modes = st.multiselect("ì„¹ì…˜ ì„ íƒ", ["main", "fs", "profit", "value"], default=["main"])
    st.session_state.loaded = st.button("ìˆ˜ì§‘/í‘œì‹œí•˜ê¸°")

if st.session_state.loaded:
    page_key_map = {"main": "c1010001", "fs": "c1030001", "profit": "c1040001", "value": "c1040001"}
    page_key = page_key_map.get("main")
    with st.spinner("encparam/id ì¶”ì¶œ ì¤‘..."):
        token = get_encparam_and_id(cmp_cd, page_key)
    encparam, cmp_id = token["encparam"], token["id"]
    if encparam and cmp_id:
        df_wide, df_long = fetch_main_table(cmp_cd, encparam, cmp_id)
        st.session_state.data_cache["df_wide"] = df_wide
        st.session_state.data_cache["df_long"] = df_long
    else:
        st.error("encparam ë˜ëŠ” id ì¶”ì¶œ ì‹¤íŒ¨")

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# í…Œì´ë¸” ë° ì°¨íŠ¸ UI
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if "df_wide" in st.session_state.data_cache:
    st.subheader("ðŸ“‹ ì£¼ìš”ìž¬ë¬´ì •ë³´ (ì™€ì´ë“œ)")
    df_wide = st.session_state.data_cache["df_wide"]
    st.dataframe(df_wide)
    st.download_button("ì—‘ì…€ ë‹¤ìš´ë¡œë“œ (Wide)", to_excel_bytes(df_wide.reset_index()), file_name=f"{cmp_cd}_main_wide.xlsx")

if "df_long" in st.session_state.data_cache:
    st.subheader("ðŸ“ˆ ì£¼ìš”ìž¬ë¬´ì •ë³´ ì°¨íŠ¸")
    df_long = st.session_state.data_cache["df_long"]
    chart_df = df_long.copy()
    chart_df["ì—°ë„"] = chart_df["ì—°ë„"].map(_extract_year_label)
    metrics = sorted(chart_df["ì§€í‘œ"].unique())
    sel_metrics = st.multiselect("ì§€í‘œ ì„ íƒ", metrics, default=metrics[:3])
    if sel_metrics:
        fig = px.line(chart_df[chart_df["ì§€í‘œ"].isin(sel_metrics)], x="ì—°ë„", y="ê°’", color="ì§€í‘œ", markers=True)
        st.plotly_chart(fig, use_container_width=True)
